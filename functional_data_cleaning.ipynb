{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75400e7b-5ba1-4416-b5d8-ce6aa91744d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed03d29-6445-41e9-b9d7-6c81800ee9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading & Familiarization ---\n",
    "def load_dataset(filepath: str) -> pd.DataFrame:\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"Dataset not found at path: {filepath}\")\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "def get_dataset_info(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"Pure function: Returns dataset structure info\"\"\"\n",
    "    return {\n",
    "        'num_rows': df.shape[0],\n",
    "        'num_columns': df.shape[1],\n",
    "        'columns': list(df.columns),\n",
    "        'dtypes': df.dtypes.to_dict(),\n",
    "        'nulls': df.isnull().sum().to_dict(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8df6216b-0883-4ded-a8c9-00de83213a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Functional Cleaning & Preprocessing ---\n",
    "\n",
    "def remove_incomplete_rows(df: pd.DataFrame, required_cols: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Filter out rows with nulls in required columns.\"\"\"\n",
    "    is_valid = lambda row: all(pd.notnull(row[col]) for col in required_cols)\n",
    "    filtered_data = list(filter(is_valid, df.to_dict(orient='records')))\n",
    "    return pd.DataFrame(filtered_data)\n",
    "\n",
    "def normalize_text_columns(df: pd.DataFrame, text_cols: List[str]) -> pd.DataFrame:\n",
    "    def normalize(text: str) -> str:\n",
    "        return text.strip().lower() if isinstance(text, str) else text\n",
    "\n",
    "    # Applying transformation using map and list comprehensions\n",
    "    records = df.to_dict(orient='records')\n",
    "    normalized_records = list(map(lambda row: {\n",
    "        col: normalize(row[col]) if col in text_cols else row[col]\n",
    "        for col in row\n",
    "    }, records))\n",
    "    return pd.DataFrame(normalized_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79e04e26-998e-4f9f-9477-a77dfa3dd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FP Refactoring Example ---\n",
    "\n",
    "def remove_null_titles(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return pd.DataFrame(filter(lambda row: pd.notnull(row['title']), df.to_dict(orient='records')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a2ae3df-2b80-4fb5-b19c-6dbd482a58e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Mini Analysis ---\n",
    "\n",
    "def get_top_categories(df: pd.DataFrame, col: str, top_n: int = 5) -> List[Tuple[str, int]]:\n",
    "    \"\"\"FP-style group count using value_counts and map\"\"\"\n",
    "    return list(df[col].value_counts().head(top_n).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6004565-d36c-47c3-bd29-30be557e9031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info: {'num_rows': 5, 'num_columns': 5, 'columns': ['show_id', 'type', 'title', 'director', 'country'], 'dtypes': {'show_id': dtype('O'), 'type': dtype('O'), 'title': dtype('O'), 'director': dtype('O'), 'country': dtype('O')}, 'nulls': {'show_id': 0, 'type': 1, 'title': 0, 'director': 1, 'country': 0}}\n",
      "Dataset Info:   show_id     type            title             director        country\n",
      "0      s1    Movie        Inception    Christopher Nolan  United States\n",
      "1      s2  TV Show     Breaking Bad       Vince Gilligan  United States\n",
      "2      s3    Movie     The Irishman      Martin Scorsese  United States\n",
      "3      s4      NaN                                   NaN  United States\n",
      "4      s5  TV Show  Stranger Things  The Duffer Brothers  United States\n",
      "Remove incomplete Dataset Info:   show_id     type            title             director        country\n",
      "0      s1    Movie        Inception    Christopher Nolan  United States\n",
      "1      s2  TV Show     Breaking Bad       Vince Gilligan  United States\n",
      "2      s3    Movie     The Irishman      Martin Scorsese  United States\n",
      "3      s5  TV Show  Stranger Things  The Duffer Brothers  United States\n",
      "Normalized Dataset Info:   show_id     type            title             director        country\n",
      "0      s1    movie        inception    Christopher Nolan  United States\n",
      "1      s2  tv show     breaking bad       Vince Gilligan  United States\n",
      "2      s3    movie     the irishman      Martin Scorsese  United States\n",
      "3      s5  tv show  stranger things  The Duffer Brothers  United States\n",
      "Remove null Dataset Info:   show_id     type            title             director        country\n",
      "0      s1    movie        inception    Christopher Nolan  United States\n",
      "1      s2  tv show     breaking bad       Vince Gilligan  United States\n",
      "2      s3    movie     the irishman      Martin Scorsese  United States\n",
      "3      s5  tv show  stranger things  The Duffer Brothers  United States\n",
      "Top 5 Types: [('movie', 2), ('tv show', 2)]\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"netflix_titles.csv\"\n",
    "    try:\n",
    "        raw_df = load_dataset(file_path)\n",
    "\n",
    "        info = get_dataset_info(raw_df)\n",
    "        print(\"Dataset Info:\", info)\n",
    "        print(\"Dataset Info:\", raw_df)\n",
    "        df_clean = remove_incomplete_rows(raw_df, required_cols=['title', 'type'])\n",
    "        print(\"Remove incomplete Dataset Info:\", df_clean)\n",
    "        df_clean = normalize_text_columns(df_clean, text_cols=['title', 'type'])\n",
    "        print(\"Normalized Dataset Info:\", df_clean)\n",
    "        df_clean = remove_null_titles(df_clean)\n",
    "        print(\"Remove null Dataset Info:\", df_clean)\n",
    "\n",
    "        print(\"Top 5 Types:\", get_top_categories(df_clean, 'type'))\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        print(\"Please make sure the dataset file exists in the correct directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c917a794-a8b1-4a85-8fce-e6b64dfbd3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:   show_id     type            title             director        country\n",
      "0      s1    Movie        Inception    Christopher Nolan  United States\n",
      "1      s2  TV Show     Breaking Bad       Vince Gilligan  United States\n",
      "2      s3    Movie     The Irishman      Martin Scorsese  United States\n",
      "3      s4      NaN                                   NaN  United States\n",
      "4      s5  TV Show  Stranger Things  The Duffer Brothers  United States\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c9f62e-79e4-40c8-a501-2aa975a046e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
